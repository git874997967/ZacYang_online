% Change the size of the paper your CV will be printed on
% by entering either a4paper or letterpaper here.
\documentclass[a4paper]{ReadableCV}

% Set color of body text
\color{black}

\begin{document}

% Set page colour using X11names colour definitions
\setPageColour{white}

% Set header details being aligned to the right or left
% If an image is displayed it will be shown on the
% opposite side to what is set here.
\setHeaderAlignment{left}

% Set colour of all headings, header highlights
\setHeadingColours{SlateGray3}

% Set image file to be displayed in header
% If left blank no image is displayed
%\setImage{profilepic.jpg}

% If image not being displayed then user can
% move contact details to opposite side of
% page to name and jobtitle.
% Use either opposite or below
\setContactLocation{opposite}

% Set up information needed for header.
% If you do not want to include certain
% information use {} instead. 
\setYourName{Zac Yang}
\setYourJobTitle{Software Data Engineer}
\setYourMobileNo{6264935215}
%\setYourHomeNo{Home phone}
\setYourEmailAddr{zacyang0701@gmail.com}
\setYourWebAddr{https://www.linkedin.com/in/zac-yang/}

% Display header information 
\showHeader{}

% Set up whether section headings are on the left or right
\setSectionAlignment{left}

% Creates a new section title / heading
\newHeading{Personal Profile}

Data/Software Engineer with a demonstrated experience on Big data solutions including databases (SQL/No-SQL) and ETL/Data pipelines using cloud services. Solid understanding of fundamental Computer Science concepts. Familiar with requirement gathering and SDLC. Great programming experience in multi-language such as Python, Java, SQL and PowerShell. Excellent problem-solving skills and software engineering habits, including peer code reviews, unit testing, etc.

\newHeading{Core Skills}

% Add up to nine core skills. If they are
% all not needed use {} instead.
\addSkills{OLTP/OLAP/ETL/ELT}
{Azure ADF/ADL/Scope script}
{AWS S3/Glue/Lambda/Athena}
{Data Visualization/Data Analyzation}
{Data Warehouse}
{Java/Python/SQL}
{PowerBI/Tableau}
{Agile/Scrum/SDLC}
{DBT/Docker}

\newHeading{Career Summary}

% Set up whether job title or company printed first
% Either use JobFirst or CompanyFirst
\setJobCompanyOrder{JobFirst}

% This displays the whole of the role information
% including dates [1], job title [2],
% company name [3] and role summary [4]
% If a full history is required use \newrole and \roleAchievements
% If only a brief description needed then just use \newrole
\newRole{2021 -- present}
{Data Engineer}
{Capital Group}
{Serve in the Investment Group. Implement ETL logic to meet business requirements from stakeholders. Technologies include but are not limited to AWS S3, Lambda, Glue, Athena, Postgres RDS and Dremio.}
\roleAchievements{Generated Glue jobs by analyzing data from different sources. Such as files in S3,CloudWatch/CloudTrail logs and other third-party APIs.}
{Utilized Glue jobs and Lambda functions to handle data processing logics with different kinds of triggers such as SQS and Glue catalog events.}
{Automated ETL process with Glue jobs by using AWS CDK which extract CloudTrail log into parquet files and dump them into Athena DB.}
{Initiated,Developed and managed an ETL pipeline. Converted IRR, MoM,FundReturnRatio and other Excel functions in Pyspark. More than 20 Lambda / Glue jobs were included for data staging, logic processing, and datasets validation. All permissions and resources access are defined in AWS CDK.}
{Persistent the ETL results into Postgre DB via AWS Glue jobs. Partitioned and indexed monthly coming datasets with pre-defined store procedures to improve performance.}
{Rendered Postgre datasets into Tableau visuals and published into different workspaces. Implemented Role-Level-Security to limit different data access requests.}
\newRole{2019 -- 2021}
{Software Data Engineer}
{Microsoft}
{Work as a software data engineer under Office IP Antispam team. Response for maintaining and upgrading the ETL/ELT data pipeline, Lens/ADF jobs, and stream dataset in
	Cosmos and ADLS with Scope script and Kusto queries. As well as generate Ad-hoc visuals with varieous tools based on different requirements. }
\roleAchievements{Migrated Cosmos uploader/downloader with ScopeSDK, T-SQL, and PowerShell from old JScript logic. Equipped with alert and pipeline monitor to enhance durability.}
{Troubleshoot issues, errors in ETL services. Generated probes, monitors, alerts for different components and services with C\#,Scope language,and PowerShell.}
{Built and maintained a big data platform (ADF/ADLS) in Cosmos Scope script as per industry standards and best practices.}
{Performed DB admin activities on the multiple DB Servers. Optimized data pipeline by rewriting new logic and SQL schema, gained both performance and service durability. Reduced up to 20\% storage cost with archiving and re-indexing stale data as well as increase the query performance.}
{Optimized slow running scope queries by using scope hints. Generate TB level data daily bases.}
{Implemented Ad-hoc data status monitors and dashboards with PowerBI and Lens platform. Delieverd reports to end users weekly and monthly.}

\newRole{2018 -- 2019}
{Data Engineer}
{Conagra Brands Inc.}
{Serve under Cost to Serve team. Generated annual reports from the sketch.  Implemented data modeling, user validation and dynamic filters based on stakeholders' requirements.}

\roleAchievements{Designed and implemented the whole ETL (Extract, Transform, Load) data process with various transactions within SSIS packages to implement business rules and logic.}
{Generated PowerBI reports, dashboards with Star schema. Implemented complex requirements in PowerBI by using DAX and M language.}
{Reduced refresh waiting time by using PowerBI API in PowerShell scripts, deployed, automated the scripts on CtrlM Servers.}
{Created customized visuals with R libraries. Embedded the PowerBI visuals within Sales-force homepage with PowerBI-JavaScriptlibraries.}
{Accumulated agile Product Management experience - a full gamut of creating stories, generated PowerBI reports and dashboards, working through user acceptance testing (UAT).}
{Hold scrum meetings as a scrum master. Wrote various documents such as data mapping document, work detail descriptions for KT sessions, and future development.}

\newRole{2013 -- 2015}
{SQL BI developer}
{KSDHC Inc.}
{As a SQL BI engineer, utilize the MS BI stack (SSIS/SSRS/SSAS) to perform ETL processes with a big scale of data. Includes data cleansing, data labeling and aggregation, etc. Generate different visuals with Microsoft SSRS.}
\roleAchievements{Created logical and physical data models based on the requirements utilizing Erwin and NaviCat.}
{Improved the performance of the official website by optimizing slowly running queries, utilized indexes, partitions, and deadlock monitor via SQL Profiler and DTA.}
{Normalized database tables to avoid redundancy and DML anomalies.}
{Developed complex SQL scripts and procedures for data profiling and auditing purposes. Combined C\# logic in SSIS packages.}
{Utilized Microsoft SSIS/SSAS/SSRS to handle ETL logic, create ad-hoc reports with both tabular model and cube model.}
{Developed various Dashboards and Stories using advanced Tableau features including calculated fields, parameters, table
	calculations, row-level security, R integration, and dashboard actions while dealing with Cloud data in SSRS.}

% move, duplicate, delete or comment out the following line if necessary
%\newpage

% This is training you have done in your own time
% \newHeading{Personal Development}

% \newCourse{2019}
% {Course title}
% {Awarding body}{}

% \newCourse{2019}
% {Course title}
% {Awarding body}{}

% \newCourse{2019}
% {Course title}
% {Awarding body}{}

% School education
\newHeading{Education}

\newCourse{2015 - 2018}{Oregon State University}{Master degree in computer science}{}
\newCourse{2010 - 2014}{Liaoning Normal University}{Bachelor degree in computer science and technology}{}

\newHeading{Certificates}

\newCourse{Microsoft:}{Azure Database Administrator Associate}{Since 2019}{}
\newCourse{Microsoft:}{Data Analyst Associate} {Since 2019}{}

\clearpage

% % Anything below creates a letter

% % Displays same header as on CV
% \showHeader



% % Name and address must be present but
% % job title is optional
% \setRecpName{Mr Deeds}
% \setRecpJobTitle{Hiring Manager}
% \setRecpRoad{BigCorp Road}
% \setRecpTown{BigCorp Town}
% \setRecpCity{BigCorp City}
% \setRecpPostcode{X12 3YZ}

% \makeLetter

% % Do not delete \recpname unless you want to call the
% % recipient something other than the name defined above.
% Dear \recpname,

% % Do not remove the following line
% \bigskip

% Please find enclosed my CV in application for the post advertised in the [insert place advertised] on [date advert seen].

% The nature of my [qualification] has prepared me for this position. It involved a great deal of independent research, requiring initiative, self-motivation and a wide range of skills. One of my courses, [insert course], an understanding of the [insert sector] industry was essential. I found this subject very interesting.

% I am a fast and accurate writer, with a keen eye for detail and I should be very grateful for the opportunity to progress. I am able to take on the responsibility of this position immediately, and have the enthusiasm and determination to ensure that I make a success of it.

% Thank you for taking the time to consider this application and I look forward to hearing from you in the near future.

% % Do not remove the following line
% \bigskip

% % comment, or uncomment, whichever you prefer to use
% Yours sincerely, % if the opening is "Dear Mr(s) Doe,"
% %Yours faithfully, % if the opening is "Dear Sir or Madam,"

% % Insert name of image with your signature
% % If paper colour is not white best to use PNG
% % with transparency.
% \closeletter{sig.png}

\end{document}